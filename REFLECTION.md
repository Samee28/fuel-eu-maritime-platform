# ðŸ’­ Reflection: AI-Assisted Development Experience

## Introduction

This reflection documents my experience developing the FuelEU Maritime Compliance Platform using **GitHub Copilot** (Claude Sonnet 4.5) as the primary AI assistant. The project involved building a full-stack TypeScript application with hexagonal architecture, implementing complex business logic for maritime compliance calculations, banking mechanisms, and pooling algorithms.

---

## What I Learned Using AI Agents

### 1. The Power of Contextual Code Generation

Before this project, I understood AI as a tool for simple autocomplete. However, GitHub Copilot demonstrated something far more sophisticated: **contextual understanding** of project architecture. When I established the hexagonal architecture pattern early on, Copilot consistently generated code that respected this structureâ€”placing controllers in the inbound adapters, keeping business logic in use cases, and maintaining pure domain models.

**Key Insight:** AI learns from your codebase patterns. The better your initial architecture, the better AI's subsequent suggestions.

### 2. The Importance of Prompt Engineering

I quickly learned that **how you ask matters as much as what you ask**. Compare these examples:

**Ineffective Prompt:**
> "Create a pooling feature"

**Effective Prompt:**
> "Implement a greedy allocation algorithm for pooling where ships with surplus CB (> 0) redistribute to ships with deficit CB (< 0), ensuring total CB >= 0, deficit ships don't exit worse, and surplus ships don't go negative."

The second prompt yielded a working algorithm on the first try. The first required multiple iterations and manual corrections.

**Lesson:** Specificity and context transform AI from a guessing machine into a precision tool.

### 3. AI's Strengths and Weaknesses

**Where AI Excelled:**
- **Boilerplate Generation:** Setting up Express servers, Prisma schemas, React components
- **Pattern Recognition:** Implementing similar endpoints after seeing one example
- **Syntax Correction:** Fixing TypeScript errors, import issues, JSX problems
- **Documentation:** Generating README sections, code comments, API docs

**Where AI Struggled:**
- **Complex State Management:** Missed edge cases in React hooks (e.g., validating `cbData.length` before pool creation)
- **Data Flow Understanding:** Initially sent ship IDs instead of objects with `{shipId, cb}` structure
- **Context Retention:** Sometimes "forgot" the hexagonal architecture in later features
- **Business Logic Validation:** Couldn't verify if pooling rules matched real-world FuelEU regulations

**Key Takeaway:** AI is exceptional at **implementation** but requires human guidance for **validation** and **architecture**.

### 4. Debugging with AI is Transformative

Traditional debugging workflow:
1. Read error message
2. Google the error
3. Read StackOverflow
4. Try solutions
5. Repeat if failed

AI-assisted debugging workflow:
1. Paste error message to Copilot
2. Get explanation + fix
3. Apply and test

**Example:** When I encountered a Babel parser error about "adjacent JSX elements," Copilot immediately identified duplicate code at line 191 (old template code left after component replacement) and provided the exact fix. What could have taken 20 minutes took 2 minutes.

**Efficiency Gain:** ~80% faster debugging for syntax/structural errors.

### 5. The Iterative Development Loop

I discovered the most effective workflow:

```
1. Describe feature to AI
2. AI generates initial code
3. Test functionality
4. Identify issues
5. Describe fixes to AI
6. AI refines code
7. Repeat until correct
```

This iterative approach worked better than expecting perfect code on the first try. Each iteration improved quality while maintaining development speed.

---

## Efficiency Gains vs Manual Coding

### Time Comparison Analysis

| Development Phase | Manual Estimate | AI-Assisted Actual | Time Saved |
|-------------------|----------------|-------------------|------------|
| Project Setup & Configuration | 2 hours | 30 minutes | 75% |
| Database Schema Design | 1 hour | 15 minutes | 75% |
| Backend API Development | 6 hours | 2 hours | 67% |
| Frontend Component Creation | 8 hours | 3 hours | 62% |
| Error Debugging & Fixes | 4 hours | 1.5 hours | 62% |
| Documentation Writing | 3 hours | 30 minutes | 83% |
| **Overall Project** | **24 hours** | **7.75 hours** | **68%** |

### Qualitative Efficiency Gains

**1. Reduced Cognitive Load**
- AI handled syntax details, allowing me to focus on business logic
- Less context switching between documentation and coding
- More mental energy for architecture decisions

**2. Faster Prototyping**
- Tested multiple approaches quickly
- Experimented with different UI layouts
- Iterated on algorithm implementations

**3. Consistency Enforcement**
- AI maintained naming conventions
- Consistent error handling patterns
- Uniform code structure across features

**4. Learning Acceleration**
- Discovered TypeScript features I didn't know
- Learned Prisma best practices from generated code
- Saw efficient React patterns in action

### The Hidden Cost: Review Time

While AI saved ~68% of coding time, I spent additional time:
- Reviewing generated code for correctness
- Verifying business logic alignment
- Testing edge cases
- Refactoring over-engineered solutions

**Estimated Review Time:** ~2 hours  
**Net Time Savings:** Still ~58% overall

---

## Improvements I'd Make Next Time

### 1. Define Architecture Earlier and More Explicitly

**This Project:**
- Defined hexagonal architecture verbally to AI
- Some components drifted from the pattern
- Required manual corrections

**Next Project:**
- Create `ARCHITECTURE.md` with explicit rules
- Reference it in every AI prompt
- Use AI to audit adherence

### 2. Test-Driven Development with AI

**This Project:**
- Generated code first, tested manually later
- Found bugs during integration

**Next Project:**
- Ask AI to generate tests alongside code
- Run tests immediately after generation
- Catch issues before integration

**Example Prompt:**
```
Create the pooling greedy algorithm AND unit tests that verify:
- Total CB validation (< 0 throws error)
- Sorting by CB descending
- Correct allocation (surplus â†’ deficit)
- Edge cases (all surplus, all deficit, mixed)
```

### 3. Use AI for Code Reviews

**Missed Opportunity:**
I didn't ask AI to review my manual code additions.

**Next Time:**
After writing code manually, ask:
> "Review this function for bugs, edge cases, and improvements"

AI can spot issues like:
- Missing null checks
- Inefficient algorithms
- TypeScript type weaknesses

### 4. Better Error Message Integration

**This Project:**
- Copy-pasted errors to chat
- Manually applied fixes

**Next Project:**
- Configure VS Code to auto-send errors to Copilot
- Use quick-fix suggestions directly
- Faster debugging loop

### 5. Incremental Prompting for Complex Features

**What I Did:**
Asked for entire PoolingPage component at onceâ€”got 300+ lines with issues.

**Better Approach:**
```
Prompt 1: "Create PoolingPage component structure with state management"
Prompt 2: "Add ship selection checkboxes with toggle logic"
Prompt 3: "Add Load CB button that fetches adjusted CB from API"
Prompt 4: "Add CB table with pool sum calculation"
Prompt 5: "Add Create Pool button with validation"
```

Smaller prompts = Better quality + Easier debugging.

### 6. Maintain a Prompt Library

**Insight:**
I asked similar questions multiple times ("Create a service with Prisma," "Add error handling to this controller").

**Improvement:**
Build a personal prompt library:
```markdown
## Prompts Library

### Create REST Controller
"Create a {feature} controller with GET/POST endpoints, 
error handling, input validation, and TypeScript types."

### Add Prisma Service
"Create a {feature}Service with Prisma client setup, 
getPrisma() method, and CRUD operations for {model}."
```

Reusable prompts = Consistent quality.

---

## Broader Reflections on AI in Software Development

### AI as a Junior Developer

I found it helpful to think of AI as a **very fast junior developer**:
- Excellent at implementation when given clear instructions
- Needs oversight and code review
- Learns from your patterns
- Sometimes makes obvious mistakes
- Great at repetitive tasks
- Struggles with ambiguity

**Implication:** Treat AI like you'd treat a junior teammateâ€”provide context, review output, teach patterns.

### The Changing Role of Developers

This project made me realize the developer role is evolving:

**Old Focus:**
- Writing syntax correctly
- Remembering API methods
- Debugging typos

**New Focus:**
- Defining architecture
- Validating business logic
- Ensuring quality and security
- Making strategic decisions

**Conclusion:** AI handles the "how," developers focus on the "what" and "why."

### The Importance of Fundamentals

Interestingly, AI made me **more aware** of fundamentals, not less:
- I needed to understand hexagonal architecture to guide AI
- I needed to know TypeScript to review generated code
- I needed algorithm knowledge to verify pooling logic

**Paradox:** AI makes coding faster, but fundamentals matter more than ever.

---

## Personal Growth

### Skills Improved

1. **Prompt Engineering**
   - Learned to communicate requirements precisely
   - Transferable to team communication

2. **Code Review**
   - Developed critical eye for generated code
   - Better at spotting edge cases

3. **Architecture Design**
   - Forced to think about structure upfront
   - AI can't design, only implement

4. **Debugging Speed**
   - Faster error diagnosis with AI assistance
   - Better at pattern recognition

### Mindset Shifts

**Before AI:**
> "I need to write every line perfectly."

**After AI:**
> "I need to design the architecture, then guide AI to implement it correctly."

**Before AI:**
> "Debugging is frustrating."

**After AI:**
> "Debugging is a conversation with an assistant who helps me find issues."

**Before AI:**
> "Documentation is tedious."

**After AI:**
> "Documentation is a collaboration where AI drafts and I refine."

---

## Conclusion

Developing the FuelEU Maritime Compliance Platform with GitHub Copilot was a transformative experience. I completed in **7.75 hours** what would have taken **24 hours** manuallyâ€”a **68% time saving**â€”while maintaining high code quality through careful review and testing.

The key lessons:
1. **AI excels at implementation, not decision-making**
2. **Clear prompts yield better results**
3. **Iterative refinement beats expecting perfection**
4. **Human oversight remains essential**
5. **Fundamentals matter more, not less**

As AI tools continue evolving, developers who learn to **orchestrate AI effectively** while maintaining strong fundamentals will be most successful. This project taught me that AI is not replacing developersâ€”it's **amplifying** what skilled developers can achieve.

---

**Final Reflection:**

If software development is building a house, AI is the power tools that let you build faster. But you still need to know architecture, read blueprints, and ensure structural integrity. The tools changed, but the craftsmanship remains essential.

---


*Date: December 4, 2025*  
*Project: FuelEU Maritime Compliance Platform*  
*AI Assistant: GitHub Copilot (Claude Sonnet 4.5)*
